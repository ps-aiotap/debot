# AI Domain Expert Chatbot

A modular AI chatbot application that answers domain-specific queries using private documentation and selected public websites, built following IndexCopilot.ai principles.

## ğŸ—ï¸ Architecture

- **Backend**: Python with LlamaIndex for RAG
- **Database**: PostgreSQL for document metadata and chat history
- **Caching**: Redis (Docker) for embeddings, API calls, and responses
- **Vector DB**: ChromaDB (Docker) for embeddings
- **UI**: Streamlit with chat interface
- **AI**: OpenAI GPT-4/3.5 + text-embedding-3-small
- **Data Sources**: PDFs, Markdown/Text docs, Web crawling

## ğŸš€ Quick Start

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure environment**:
   - Update `.env` with your OpenAI API key
   - Ensure PostgreSQL is running (port 5434)

3. **Start Docker services**:
   ```bash
   python start.py
   # Or manually: docker-compose up -d
   ```

4. **Add your data**:
   - Place PDFs in `./data/pdfs/`
   - Place documents in `./data/docs/`
   - Configure websites in `config.yaml`

5. **Setup and index data**:
   ```bash
   python setup.py
   ```

6. **Run the Streamlit app**:
   ```bash
   streamlit run streamlit_app.py
   ```

## ğŸ“ Project Structure

```
debot/
â”œâ”€â”€ ingest/                 # Data ingestion modules
â”‚   â”œâ”€â”€ load_docs.py       # Markdown/text loader
â”‚   â”œâ”€â”€ load_pdfs.py       # PDF parser with caching
â”‚   â”œâ”€â”€ crawler.py         # Async web crawler
â”‚   â””â”€â”€ load_chat_logs.py  # Future: Slack/Teams support
â”œâ”€â”€ providers/             # LLM providers (from IndexCopilot.ai)
â”œâ”€â”€ data/                  # Data directories
â”‚   â”œâ”€â”€ docs/             # Documents (.md, .txt)
â”‚   â””â”€â”€ pdfs/             # PDF files
â”œâ”€â”€ cache_utils.py         # Redis caching utilities
â”œâ”€â”€ embedding_service.py   # Embedding & indexing
â”œâ”€â”€ qa_service.py         # RAG query engine
â”œâ”€â”€ database.py           # PostgreSQL models
â”œâ”€â”€ main.py               # Application orchestrator
â”œâ”€â”€ streamlit_app.py      # Streamlit UI
â”œâ”€â”€ setup.py              # Setup script
â”œâ”€â”€ start.py              # Docker startup script
â”œâ”€â”€ docker-compose.yml    # Docker services
â”œâ”€â”€ config.yaml           # Configuration
â””â”€â”€ .env                  # Environment variables
```

## âš™ï¸ Configuration

### Environment Variables (.env)
- `OPENAI_API_KEY`: Your OpenAI API key
- `POSTGRES_*`: PostgreSQL connection settings
- `REDIS_HOST`, `REDIS_PORT`: Redis Docker connection
- `CHROMA_HOST`, `CHROMA_PORT`: ChromaDB Docker connection
- `PDF_DIR`, `DOCS_DIR`: Data directories

### Config File (config.yaml)
- Crawling settings (URLs, depth, limits)
- Embedding and retrieval parameters
- LLM model configuration

## ğŸ”§ Features

- **Multi-source ingestion**: PDFs, documents, websites
- **PostgreSQL storage**: Document metadata and chat history
- **Docker services**: Redis and ChromaDB in containers
- **Redis caching**: Embeddings, crawled content, responses
- **Source filtering**: docs only, web only, or all
- **Async crawling**: Respects robots.txt, handles rate limits
- **Chat interface**: Streamlit with source citations
- **Modular design**: Easy to extend and maintain

## ğŸ”„ Usage

### CLI Mode
```bash
python main.py
```

### Web Interface
```bash
streamlit run streamlit_app.py
```

### Programmatic Usage
```python
from main import ChatbotApp

app = ChatbotApp()
await app.initialize()
response = app.ask_question("Your question here")
```

## ğŸ§ª Phase 2 Preparation

The `ingest/load_chat_logs.py` module is prepared for future Slack/Teams support chat ingestion.

## ğŸ“ Notes

- All caching uses Redis (Docker) with configurable TTL
- Embeddings are cached by content hash
- Web content respects robots.txt by default
- Vector database runs in ChromaDB Docker container
- Document metadata and chat history stored in PostgreSQL
- Services can be started with `python start.py`